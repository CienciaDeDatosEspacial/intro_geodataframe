{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq_-jS9HtUU-"
   },
   "source": [
    "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cCaZ1r2tUVA"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/CienciaDeDatosEspacial/intro_geodataframe/blob/main/index.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# The Geo Dataframe\n",
    "\n",
    "The geodataframe (GDF) is a dataframe (DF) where every row represents an spatial element (point, line, polygon).\n",
    "\n",
    "Historically, the most common file type that stores spatial elements is the shapefile. Let's take a look at some of them:\n",
    "\n",
    "1. In GitHub (cloud), create a repository named: introgeodf.\n",
    "2. Clone that repo to a local folder in your computer.\n",
    "3. In that local folder in your computer, create a folder named **maps**.\n",
    "4. Go to **Paidea** and download three compressed files from the folder **WorldMaps**.\n",
    "5. Download those files into the folder **maps** in your computer: *countries*, *cities*, and *rivers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhGJmen1tUVB"
   },
   "source": [
    "You may see something like this:\n",
    "\n",
    "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/mapsFolderImage.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBs3ovRstUVB"
   },
   "source": [
    "You can decompress those files:\n",
    "\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/folderRar_1.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzvFDa2JtUVB"
   },
   "source": [
    "Now, take a look a **World_Countries**:\n",
    "\n",
    "<img src=\"https://github.com/CienciaDeDatosEspacial/code_and_data/blob/main/imageCountries_shp.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUOIWMOTtUVB"
   },
   "source": [
    "There, you see that this **one map** requires **several files**. That is the nature of the shapefile.\n",
    "\n",
    "Let's read the file with the help of **geopandas**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJV5G0POtUVB"
   },
   "outputs": [],
   "source": [
    "import os, geopandas as gpd\n",
    "\n",
    "countries=gpd.read_file(os.path.join(\"maps\",\"World_Countries\",\"World_Countries.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5AOj3mktUVC"
   },
   "source": [
    "Let's use some familiar DF functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTVBGfNatUVC"
   },
   "outputs": [],
   "source": [
    "# what is it?\n",
    "type(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkvWskZytUVC"
   },
   "outputs": [],
   "source": [
    "# dimensions\n",
    "countries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETJdBBR1tUVD"
   },
   "outputs": [],
   "source": [
    "# names\n",
    "countries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrbZt4g5tUVD"
   },
   "outputs": [],
   "source": [
    "# some content\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPHdGEtatUVD"
   },
   "outputs": [],
   "source": [
    "# any missing values?\n",
    "countries[countries.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWXmBv-vtUVD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# types\n",
    "countries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzT4ctrjtUVD"
   },
   "source": [
    "As you see, those pandas commands are working fine, but now we have a new column type: **geometry**. Let's see this map of countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjMj9myHtUVD"
   },
   "outputs": [],
   "source": [
    "countries.plot(facecolor=\"azure\",#color of polygon fill\n",
    "               edgecolor='black', #color of lines\n",
    "               linewidth=0.1) #thickness of lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCtifGnqtUVD"
   },
   "source": [
    "Let's open the other maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPbJ4wFHtUVD"
   },
   "outputs": [],
   "source": [
    "rivers=gpd.read_file(os.path.join(\"maps\",\"World_Hydrography\",\"World_Hydrography.shp\"))\n",
    "cities=gpd.read_file(os.path.join(\"maps\",\"World_Cities\",\"World_Cities.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the rivers map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Gap_au4tUVD"
   },
   "outputs": [],
   "source": [
    "rivers.plot(edgecolor='blue',\n",
    "            linewidth=1,\n",
    "            linestyle='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the cities map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nAC2GkptUVD"
   },
   "outputs": [],
   "source": [
    "cities.plot(marker='.', # marker type\n",
    "            color='red',\n",
    "            markersize=1,\n",
    "            alpha=0.3) # transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prkK6IA8tUVE"
   },
   "source": [
    "You can plot all the layers, as long as they share the same projection.\n",
    "Let's verify that all have the same projection (**CRS**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G0MkpZ1tUVE"
   },
   "outputs": [],
   "source": [
    "countries.crs==cities.crs==cities.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOiFM3uYtUVE"
   },
   "source": [
    "You can start by creating the layer on the back (the base), and add layers on top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqkVAvHstUVE"
   },
   "outputs": [],
   "source": [
    "base = countries.plot(facecolor=\"white\",\n",
    "                      edgecolor='black',\n",
    "                      linewidth=0.1,\n",
    "                      figsize=(12,12))\n",
    "\n",
    "rivers.plot(edgecolor='blue', linewidth=0.4,\n",
    "            ax=base)# on top of...\n",
    "cities.plot(marker='.', color='red', markersize=1,alpha=0.7,\n",
    "            ax=base) # on top of...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving into a different format (not shapefile):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give you ONE file, with three maps as layers 'inside':\n",
    "# countries.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='countryBorders', driver=\"GPKG\")\n",
    "# rivers.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='riverLines', driver=\"GPKG\")\n",
    "# cities.to_file(os.path.join(\"maps\",\"worldMap.gpkg\"),layer='cityPoints', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WVBq3bUtUVE"
   },
   "source": [
    "## Subsetting\n",
    "\n",
    "You can subset your map by *filtering*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsiI-8ZYtUVE"
   },
   "outputs": [],
   "source": [
    "brazil=countries[countries.COUNTRY=='Brazil']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biux_VKutUVF"
   },
   "source": [
    "But you can also subset by *clipping*, as sometimes other data frames may not have the same fields for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltxxI2OotUVF"
   },
   "outputs": [],
   "source": [
    "citiesBrazil_clipped = gpd.clip(gdf=cities,\n",
    "                          mask=brazil)\n",
    "riversBrazil_clipped = gpd.clip(gdf=rivers,\n",
    "                               mask=brazil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nXd5aiRtUVF"
   },
   "source": [
    "Then, you can plot the clipped version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEfKc5nQtUVF"
   },
   "outputs": [],
   "source": [
    "base = brazil.plot(facecolor=\"greenyellow\", edgecolor='black', linewidth=0.4,figsize=(5,5))\n",
    "citiesBrazil_clipped.plot(marker='+', color='red', markersize=15,\n",
    "                    ax=base)\n",
    "riversBrazil_clipped.plot(edgecolor='blue', linewidth=0.5,\n",
    "                    ax=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check what geometries you have in your GDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citiesBrazil_clipped.geom_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "riversBrazil_clipped.geom_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the amount of elements (rows) is different, and that all those elements do not belong to the exact geometry type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnrWwUWZtUVG"
   },
   "source": [
    "### Exercise 1\n",
    "<div class=\"alert-success\">\n",
    "\n",
    "1. Follow the same steps in this last section to plot three maps of one country. Do not use Brazil.\n",
    "2. Plot your three layers.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "## Map Projection\n",
    "\n",
    "The CRS is a very important property of the maps. They affect three some aspects:\n",
    "\n",
    "* shape\n",
    "* area\n",
    "* scale\n",
    "* direction\n",
    "\n",
    "Most maps come with a default CRS: 4326. Pay attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check units\n",
    "brazil.crs.axis_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.crs.is_projected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polygons have a centroid. When we try getting a centroid from an **unprojected** polygon, you get: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centroid\n",
    "brazil.centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reprojecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A projected CRS will have units in meters or feet (or similar). You can request a crs per country [here](https://epsg.io/?q=brazil+kind%3APROJCRS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended for Brazil (meters)\n",
    "brazil.to_crs(5641).crs.axis_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now this works with no warning\n",
    "brazil.to_crs(5641).centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replotting:\n",
    "\n",
    "base5641=brazil.to_crs(5641).plot()\n",
    "brazil.to_crs(5641).centroid.plot(color='red',ax=base5641)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the projected version for all our maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil_5641=brazil.to_crs(5641)\n",
    "\n",
    "cities_brazil_5641=citiesBrazil_clipped.to_crs(brazil_5641.crs)\n",
    "\n",
    "rivers_brazil_5641=riversBrazil_clipped.to_crs(brazil_5641.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving \n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "# brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='country', driver=\"GPKG\")\n",
    "# cities_brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='cities', driver=\"GPKG\")\n",
    "# rivers_brazil_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='rivers', driver=\"GPKG\")\n",
    "# brazil_5641.centroid.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='centroid', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "<div class=\"alert-success\">\n",
    "\n",
    "1. Reproject your country's map layers.\n",
    "2. Plot the reprojected layers\n",
    "3. Save the reprojected layers\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "## Creating Spatial data\n",
    "\n",
    "You will get Lines and Polygons as maps for sure, but that may not be the case with points. Let me download a **CSV** file with information on the airports in Brazil from this [website](https://data.humdata.org/dataset/ourairports-bra), I will save it in my **data** folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "infoairports=pd.read_csv(os.path.join(\"data\",\"br-airports.csv\"))\n",
    "\n",
    "# some rows\n",
    "\n",
    "infoairports.iloc[[0,1,2,3,-4,-3,-2,-1],:] #head and tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs some cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bye first row \n",
    "infoairports.drop(index=0,inplace=True)\n",
    "infoairports.reset_index(drop=True, inplace=True)\n",
    "infoairports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the  columns needed\n",
    "\n",
    "infoairports.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep=['name','type','latitude_deg', 'longitude_deg','elevation_ft','region_name','municipality']\n",
    "infoairports=infoairports.loc[:,keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoairports.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols=['latitude_deg', 'longitude_deg','elevation_ft']\n",
    "infoairports[numericCols]=infoairports.loc[:,numericCols].apply(lambda x:pd.to_numeric(x))\n",
    "\n",
    "# now \n",
    "infoairports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot\n",
    "\n",
    "base = brazil_5641.plot(color='white', edgecolor='black') #unprojected\n",
    "\n",
    "infoairports.plot.scatter(x = 'longitude_deg', y = 'latitude_deg',ax=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is it wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports=gpd.GeoDataFrame(data=infoairports.copy(),\n",
    "                 geometry=gpd.points_from_xy(infoairports.longitude_deg,\n",
    "                                             infoairports.latitude_deg), \n",
    "                 crs=brazil.crs.to_epsg())# the coordinates were in degrees - unprojected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does it look better?\n",
    "\n",
    "# let's plot\n",
    "\n",
    "base = brazil_5641.plot(color='white', edgecolor='black')\n",
    "airports.plot(ax=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember:\n",
    "type(airports), type(infoairports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep the projected version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_5641=airports.to_crs(5641)\n",
    "\n",
    "## then\n",
    "\n",
    "base = brazil_5641.plot(color='white', edgecolor='black')\n",
    "airports_5641.plot(ax=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change size\n",
    "\n",
    "base = brazil_5641.plot(color='white', edgecolor='black')\n",
    "airports_5641.plot(ax=base, markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember you have type of airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_5641['type'].value_counts() # this will not work: airports.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use that in the future. For now, just rename the **type** column to a different one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_5641.rename(columns={'type':'kind'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding the airports to GPKG\n",
    "# airports_5641.to_file(os.path.join(\"maps\",\"brazilMaps_5641.gpkg\"), layer='airports', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "<div class=\"alert-success\">\n",
    "\n",
    "1. Find the airports for your country [here](https://ourairports.com/data/). The data is in a CSV file.\n",
    "2. Create projected layer of airports.\n",
    "3. Plot all the layers and airports on top.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Merging\n",
    "\n",
    "Remember we have these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map has no interesting information beyond the geometry. Let me bring this info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragilityCiaLink=\"https://github.com/CienciaDeDatosEspacial/merging/raw/main/FragilityCia_isos.csv\"\n",
    "\n",
    "fragilityCia=pd.read_csv(fragilityCiaLink)\n",
    "\n",
    "fragilityCia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to add the _fragilityCia_ data into the map. That is the merging process. \n",
    "For that, we need a common column. The _Country_ column is the option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to upper case.\n",
    "countries['COUNTRY']=countries.COUNTRY.str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very unlikely the names are written the same. Verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
    "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyFragilCia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here\n",
    "onlyMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find similar names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process\n",
    "\n",
    "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting\n",
    "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia) \n",
    " if process.extractOne(country,onlyMap)[1]>=90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a _dict_ of changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then:\n",
    "try1={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragilCia) \n",
    " if process.extractOne(country,onlyMap)[1]>=90}\n",
    "try1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making changes and updating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragilityCia.replace(to_replace={'Country':try1},inplace=True)\n",
    "\n",
    "# updating\n",
    "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
    "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)\n",
    "# new matches\n",
    "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some manual\n",
    "\n",
    "countries[countries.COUNTRY.str.contains('LAO|ESW|SWA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manualChanges={'SWAZILAND':'ESWATINI','LAOS':\"LAO PEOPLE'S DEMOCRATIC REPUBLIC (THE)\"}\n",
    "\n",
    "countries.replace(to_replace={'COUNTRY':manualChanges},inplace=True)\n",
    "\n",
    "# updating\n",
    "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
    "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)\n",
    "# new matches\n",
    "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then:\n",
    "try2={country: process.extractOne(country,onlyMap)[0] for country in sorted(onlyFragilCia)}\n",
    "try2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing\n",
    "fragilityCia.replace(to_replace={'Country':try2},inplace=True)\n",
    "\n",
    "# new update\n",
    "onlyFragilCia=set(fragilityCia.Country)- set(countries.COUNTRY)\n",
    "onlyMap=set(countries.COUNTRY)- set(fragilityCia.Country)\n",
    "\n",
    "# new matches\n",
    "[(country, process.extractOne(country,onlyMap)) for country in sorted(onlyFragilCia)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not improve the situation.\n",
    "\n",
    "Now, when you merge a GDF with a DF, **the GDF has to be on the left**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMapAndData=countries.merge(fragilityCia,left_on='COUNTRY', right_on='Country')\n",
    "\n",
    "theMapAndData.drop(columns=['Country'],inplace=True) # no need for this column\n",
    "# here it is (new map):\n",
    "theMapAndData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "\n",
    "1. Use the column _region_  to keep the American continent.\n",
    "2. Compute the centroids of the countries in America.      \n",
    "3. Use the centroids to represent the fragility based on size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choropleths\n",
    "\n",
    "We should plan how to color the polygons based on some variable, let me check our variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMapAndData.iloc[:,[7,8,11]].plot(kind='box',logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are in different units, we should try a data rescaling strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **StandardScaler**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normalized_data = scaler.fit_transform(theMapAndData.iloc[:,[7,8,11]])\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare column names\n",
    "namesForNormalized=theMapAndData.iloc[:,[7,8,11]].columns + '_z'\n",
    "namesForNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result as data frame\n",
    "data_Z=pd.DataFrame(normalized_data,columns=namesForNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot result\n",
    "data_Z.plot(kind='box')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MinMaxScaler**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "scaled_data=scaler.fit_transform(theMapAndData.iloc[:,[7,8,11]])\n",
    "namesForScaled=theMapAndData.iloc[:,[7,8,11]].columns + '_mM'\n",
    "data_mM=pd.DataFrame(scaled_data,columns=namesForScaled)\n",
    "data_mM.plot(kind='box') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **RobustScaler**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "robScaled_data = scaler.fit_transform(theMapAndData.iloc[:,[7,8,11]])\n",
    "namesForRbScaled=theMapAndData.iloc[:,[7,8,11]].columns + '_rB'\n",
    "data_rB=pd.DataFrame(robScaled_data,columns=namesForRbScaled)\n",
    "\n",
    "data_rB.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **QuantileTransformer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "scaler = QuantileTransformer(n_quantiles=30, random_state=0,output_distribution='normal') #or 'uniform'\n",
    "QtScaled_data = scaler.fit_transform(theMapAndData.iloc[:,[7,8,11]])\n",
    "namesForQtScaled=theMapAndData.iloc[:,[7,8,11]].columns + '_Qt'\n",
    "data_Qt=pd.DataFrame(QtScaled_data,columns=namesForQtScaled)\n",
    "\n",
    "data_Qt.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will keep the _data_Qt_ data frame. Now, I want cut the data.\n",
    "Please install [**numba**](https://numba.readthedocs.io/en/stable/user/installing.html) before runing the next code; also make sure you have **pysal**, **mapclassify** and **numpy** installed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip show numba mapclassify numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me discretize **fragility_Qt**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapclassify \n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12345) # so we all get the same results!\n",
    "\n",
    "# let's try 5 intervals\n",
    "K=5\n",
    "theVar=data_Qt.fragility_Qt\n",
    "# same interval width, easy interpretation\n",
    "ei5 = mapclassify.EqualInterval(theVar, k=K)\n",
    "# same interval width based on standard deviation, easy - but not as the previous one, poor when high skewness\n",
    "msd = mapclassify.StdMean(theVar)\n",
    "# interval width varies, counts per interval are close, not easy to grasp, repeated values complicate cuts                                \n",
    "q5=mapclassify.Quantiles(theVar,k=K)\n",
    "\n",
    "# based on similarity, good for multimodal data \n",
    "mb5 = mapclassify.MaximumBreaks(theVar, k=K)\n",
    "# based on similarity, good for skewed data\n",
    "ht = mapclassify.HeadTailBreaks(theVar) # no K needed\n",
    "# based on similarity, optimizer\n",
    "fj5 = mapclassify.FisherJenks(theVar, k=K)\n",
    "# based on similarity, optimizer\n",
    "jc5 = mapclassify.JenksCaspall(theVar, k=K)\n",
    "# based on similarity, optimizer\n",
    "mp5 = mapclassify.MaxP(theVar, k=K) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we select the right classification?\n",
    "Let me use the the Absolute deviation around class median (ADCM) to make the comparisson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class5 = ei5,msd, q5,mb5,  ht, fj5, jc5, mp5\n",
    "# Collect ADCM for each classifier\n",
    "fits = np.array([ c.adcm for c in class5])\n",
    "# Convert ADCM scores to a DataFrame\n",
    "adcms = pd.DataFrame(fits)\n",
    "# Add classifier names\n",
    "adcms['classifier'] = [c.name for c in class5]\n",
    "# Add column names to the ADCM\n",
    "adcms.columns = ['ADCM', 'Classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the **adcms**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adcms.sort_values('ADCM').plot.barh(x='Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the best strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Qt['fragility_Qt_jc5'] = jc5.yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there you are\n",
    "data_Qt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the mean of 'fragility_Qt' by the labels of the columns created (from '0' to '4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexList=['fragility_Qt_jc5']\n",
    "aggregator={'fragility_Qt': ['mean']}\n",
    "\n",
    "pd.concat([data_Qt[['fragility_Qt',col]].groupby(col,as_index=False).agg(aggregator) for col in indexList],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the data to the map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theMapAndData=theMapAndData.assign(fragility_Qt=data_Qt.fragility_Qt.values,\n",
    "                                   fragility_Qt_jc5=data_Qt.fragility_Qt_jc5.values)\n",
    "theMapAndData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming\n",
    "newLabelsForLevels={0:\"0_Great\", 1:\"1_Good\", 2:\"2_Middle\", 3:\"3_Bad\", 4:\"4_Poor\"}\n",
    "\n",
    "theMapAndData['fragility_Qt_jc5_cat']=theMapAndData.loc[:,'fragility_Qt_jc5'].replace(newLabelsForLevels)\n",
    "theMapAndData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready for a choropleth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "theMapAndData.plot(column='fragility_Qt_jc5_cat', # variable to plot\n",
    "                   cmap='viridis', # set of colors\n",
    "                   categorical=True, # can be interpreted as category\n",
    "                   edgecolor='white', # border color\n",
    "                   linewidth=0., # width of border\n",
    "                   alpha=1, # level of transparency (0 is invisible)\n",
    "                   legend=True, # need a legend?\n",
    "                   # location of legend: 'best', 'upper right', 'upper left', 'lower left',\n",
    "                   # 'lower right', 'right', 'center left', 'center right',\n",
    "                   # 'lower center', 'upper center', 'center'\n",
    "                   legend_kwds={'loc':\"lower left\"}, \n",
    "        ax=ax\n",
    "       )\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, once you know the ADCM, you can request the choropleth without creating a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "theMapAndData.plot(column='fragility_Qt', \n",
    "                   cmap='OrRd', \n",
    "                   scheme=\"jenkscaspall\",k=5,\n",
    "        edgecolor='grey', \n",
    "        linewidth=0.5, \n",
    "        alpha=1, \n",
    "        legend=True,\n",
    "        legend_kwds={'loc':3},\n",
    "        ax=ax\n",
    "       )\n",
    "\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<div class=\"alert-success\">\n",
    "\n",
    "1. Transform the co2 and forest variables.\n",
    "2. Make the maps for the co2 and forest variables.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "test"
  },
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
